---
title: Creating an On-Demand Service Tile
owner: London Services Enablement
---

This documents the process for deploying an on-demand broker (ODB) with a service in a single tile, on a AWS installation of Ops Manager v1.8. 
Pivotal has built a reference [Kafka tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile).

## <a id="requirements"></a>Requirements

Before ODB, Ops Manager controlled the IP allocation of the private networks.
So when using the ODB in a tile, you need at least two private networks:

- A network where Ops Manager will deploy the on-demand broker VM
- A different network where the on-demand broker will deploy service instance VMs

The network for service instances should be flagged as a Service Network in Ops Manager.

## <a id="deploying"></a>Deploying Ops Manager to AWS

1. Follow the default Ops Manager deployment [documentation](https://docs.pivotal.io/pivotalcf/customizing/cloudform-template.html), but with these modifications:
  1. Create a self-signed wildcard SSL certificate for a domain you control.
     This is usually `*.SOME-SUBDOMAIN.cf-app.com`.
     Upload the certificate (along with the associated private key) to AWS. 
  For details, see [SSL/TLS Certificates for Classic Load Balancers](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ssl-server-cert.html#create-cert).
  1. Download the CloudFormation JSON and save it in the Ops Manager directory.
  1. Run the CloudFormation stack. Save any pertinent inputs (e.g BOSH DB credentials) you type into the web console 
  in the Ops Manager directory for safe keeping (for example, in `info.txt`).
  1. Launch an instance of the AMI. If possible, use an elastic IP so that you can always keep the same DNS record
   even if you recreate the VM. Failing that, auto-assign a public IP.
  1. Create a DNS record for `pcf.WILDCARD-CERTIFICATE-DOMAIN`. To use the earlier example, the record will be for `pcf.some-subdomain.cf-app.com`. It should point to the public IP of the Ops Manager VM.
1. Continue following the docs to log in to Ops Manager. Save the login credentials.
1. Configure the BOSH Director tile.
1. Click **Apply Changes**, and record the BOSH init manifest for future reference. 
   For example, copy the manifest to your local machine, with the following command:

    ```
    scp -i PRIVATE-KEY.pem ubuntu@OPSMAN-IP:/var/tempest/workspaces/default/deployments/bosh.yml bosh.yml
    ```

<p class="note"><strong>Note</strong>: The ELBs created by CloudFormation are both for CF, not Ops Manager. 
  One of them will be configured with your wildcard certificate. This takes the place of HAProxy in AWS PCF deployments, 
  and is therefore not used until you deploy the ERT tile.</p>

###<a id="target_bosh"></a>Target the BOSH Director

To target the BOSH Director from the Ops Manager VM, use a command like the following:

<pre class=terminal>$ bosh2 --ca-cert /var/tempest/workspaces/default/root_ca_certificate -e 10.0.16.10 alias-env om-director</pre>

Thereafter, use `bosh2 -e om-director` to make requests to the BOSH Director.

## <a id="building"></a>Build a Tile

1. Follow the instructions in the topic
[Tile Generator](http://docs.pivotal.io/tiledev/tile-generator.html)
to build your service tile.
1. Add the accessors listed in [Accessors](#accessors) to the tile metadata file. 
This file is named `tile.yml` if you used the Tile Generator.
To use the `$self` accessors, set the `service-broker` flag to `true` in the tile metadata file.

## <a id="accessors"></a>Mandatory Accessors to Configure an On-Demand Tile

The on-demand broker requires configuration information about the bosh director. 
Tile authors must add accessors to the tile metadata file to configure 
the manifest with values that Ops Manager operators cannot access. 
<br><br>
The following accessors are mandatory for the on-demand broker configuration:

<p class="note"><strong>Note</strong>: For more accessors, see the 
[ops-manager-example product](https://github.com/pivotal-cf-experimental/ops-manager-example/blob/master/example-product/metadata/example-product.yml.erb).
</p>

#### director

Ops Manager uses these accessors to get values relating to the BOSH Director installation.
For the on-demand broker to interact with bosh director, the on-demand service tile 
must be configured with credentials for managing bosh deployments.  

The following table lists the accessors you must add:

| Accessor                  | Description                                                                                                                    |
|:--------------------------|:-------------------------------------------------------------------------------------------------------------------------------|
| $director.hostname        | The director's hostname or IP address                                                                                                      |
| $director.ca\_public\_key | The director's root ca certificate. Related: [how to configure SSL certificates for the ODB](operating.html#ssl-certificates). |

For example

```yaml
bosh:
  url: https://(( $director.hostname )):25555
  root_ca_cert: (( $director.ca_public_key ))
```

To see this example in context, see the 
[example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L104-L106).

#### self

Ops Manager uses these accessors to get values that have been assigned to the tile after installation.
To enable `$self` accessors, set `service_broker: true` at the top level of your
tile metadata file.

<p class="note"><strong>Note</strong>: Setting <code>service_broker: true</code>
  will cause the BOSH Director to redeploy when installing or uninstalling the tile.</p>

The following table lists the accessors you must add:

| Accessor                  | Description                                                     |
|:--------------------------|:----------------------------------------------------------------|
| $self.uaa\_client_name    | UAA client name, that can authenticate with the BOSH Director   |
| $self.uaa\_client\_secret | UAA client secret, that can authenticate with the BOSH Director |
| $self.stemcell\_version   | The stemcell that the service deployment uses                   |
| $self.service\_network    | Service network configured for the on-demand instances          |

The service network has to be created manually. 
Create a subnet on AWS and then add it to the director. 
In the director tile, under Create Networks > ADD network > fill in the subnet/vpc details.

For example

```yaml
bosh:
  authentication:
    uaa:
      url: https://(( $director.hostname )):8443
      client_id: (( $self.uaa_client_name ))
      client_secret: (( $self.uaa_client_secret ))
```

To see this example in context, see the 
[example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L107-L111).

#### (Optional) cf

Ops Manager uses these accessors to get values from the PAS (or Elastic Runtime) 
tile in the Ops Manager installation.
If you want to use Pivotal Application Service (PAS) or Elastic Runtime, add 
these accessors to your tile metadata file.

The following table lists the accessors you must add to use PAS (or Elastic Runtime):

| Accessor                                        | Description                                                                        |
|:------------------------------------------------|:-----------------------------------------------------------------------------------|
| ..cf.ha\_proxy.skip\_cert\_verify.value         | Flag to skip SSL certificate verification for connections to the CF API            |
| ..cf.cloud\_controller.apps\_domain.value       | The application domain configured in the CF installation                           |
| ..cf.cloud\_controller.system\_domain.value     | The system domain configured in the CF installation                                |
| ..cf.uaa.system\_services\_credentials.identity | Username of a CF user in the cloud\_controller.admin group, to be used by services |
| ..cf.uaa.system\_services\_credentials.password | Password of a CF user in the cloud\_controller.admin group, to be used by services |

For example

```yaml
disable_ssl_cert_verification: (( ..cf.ha_proxy.skip_cert_verify.value ))
cf:
  url: https://api.(( ..cf.cloud_controller.system_domain.value ))
  authentication:
    url: https://uaa.(( ..cf.cloud_controller.system_domain.value ))
    user_credentials:
      username: (( ..cf.uaa.system_services_credentials.identity ))
      password: (( ..cf.uaa.system_services_credentials.password ))
```

To see this example in context, see the
[example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L103-L119).

## <a id="public-ip"></a>Public IP Address for On-Demand Service Instance Groups

Ops Manager v1.9 and later provides a VM extension called `public_ip` in the BOSH Director's cloud config.
This can be used in the on-demand service broker's manifest to give instance groups a public IP address. This IP is only used for outgoing traffic to the internet from VMs with the `public_ip` extension. All internal traffic / incoming connections need to go over the private IP.

Here is an example showing how to allow operators to assign a public IP address to an on-demand service instance group in the tile handcraft:

```
form_types:
- name: example_form
  property_inputs:
  - reference: .broker.example_vm_extensions
    label: VM options
    description: List of VM options for Service Instances

job_types:
- name: broker
  templates:
  - name: broker
    release: on-demand-service-broker
    manifest: |
      service_catalog:
        plans:
        - name: example-plan
          instance_groups:
          - name: example-instance-group
            vm_extensions: (( .broker.example_vm_extensions.value ))
  property_blueprints:
  - name: example_vm_extensions
    type: multi_select_options
    configurable: true
    optional: true
    options:
    - name: "public_ip"
      label: "Internet Connected VMs (on supported IaaS providers)"
```

## <a id="floating-stemcell"></a>Floating Stemcells

Ops Manager provides a feature called [Floating Stemcells](https://docs.pivotal.io/pivotalcf/1-9/customizing/understanding-stemcells.html) that allows PCF to quickly propagate a patched stemcell to all VMs in the deployment that have the same compatible stemcell. Both the broker deployment and the service instances deployed by the On-Demand Broker can make use of this feature. Enabling this feature can help ensure that all of your service instances are patched to the latest stemcell.

For the service instances to be installed automatically with the latest stemcell,
you need to make sure the `upgrade-all-service-instances` errand is ticked.

Here is an example of how to implement floating stemcells in `handcraft.yml`:

```
job_types:
  templates:
  - name: broker
    manifest: |
      service_deployment:
        releases:
        - name: release-name
          version: 1.0.0
          jobs: [job_server]
        stemcell:
          os: ubuntu-trusty
          version: (( $self.stemcell_version ))
```

Here is an example of how to configure the `stemcell_criteria` in `binaries.yml`:

```
---
name: example-on-demand-service
product_version: 1.0.0
stemcell_criteria:
  os: ubuntu-trusty
  version: '3312'
  enable_patch_security_updates: true
```

<p class="note"><strong>Note</strong>: Configuring this value to <code>false</code> disables this feature.</p>

## <a id="errands"></a>On-Demand Broker Errands

In the reference [Kafka tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile)
we have demonstrated how the errands in the on-demand broker release can be used.

The errands should be specified in the following order, as shown in the example Kafka tile:

Post-deploy:

- `register-broker`
- `upgrade-all-service-instances`

Pre-delete:

- `delete-all-service-instances-and-deregister-broker`

These errands are documented in the [operating section](operating.html#management).

### Upgrade All Service Instances Errand

The `upgrade-all-service-instances` errand can be configured with two
parameters:

- The number of simultaneous upgrades

- The number of canary instances

For more information about these parameters, see
[Upgrade All Service Instances](operating.html#upgrade-all-instances).

The example [Kafka
tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile)
shows how to create a tab with fields to configure the parameters for this errand.
The example tile has constraints to ensure the number of simultaneous
upgrades is greater than one and the number of canaries is greater than zero.

## <a id="secure-creds"></a>Secure Binding Credentials

Runtime CredHub can securely store service instance credentials.
To include this feature in your tile, make some changes to the tile metadata, as described below:

1. Add `secure_binding_credentials` to the top-level properties block in the on-demand broker manifest. For example:

    ```yaml
    secure_binding_credentials:
      enabled: true
      authentication:
        uaa:
          client_id: CREDHUB_CLIENT_ID # client ID used by broker when communicating with CredHub
          client_secret: CREDHUB_CLIENT_SECRET # client secret used by broker when communicating with CredHub
          ca_cert: UAA_CA_CERT
    ```

2. To let users enable and disable this feature in the Ops Manager UI, you need to make some changes to your tile's metadata file:
  1. Add a form field to allow the user to enable/disable secure bindings
  ([example](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L39-L46)).
  1. Add an element in `property_blueprints` that reads the setting in the form
  field and exposes the appropriate manifest snippet for CredHub and secure binding
  ([example](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L606-L632)).
  1. Change the `broker` job so that it consumes the CredHub BOSH link from the
  above manifest snippet
  ([example](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L96)).
  1. Change the `broker` job so that it consumes the generated secure bindings
  manifest snippet
  ([example](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L112)).

<p class="note">To use the secure binding credentials feature you must use Pivotal Cloud Foundry (PCF) 2.0 or later.</p>
