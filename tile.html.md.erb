---
title: Creating an On-Demand Service Tile
owner: London Services Enablement
---

This documents the process for deploying an on-demand broker (ODB) with a service 
in a single tile, on a AWS installation of Ops Manager v1.8. 
Pivotal has built a reference [Kafka 
tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile).

## <a id="requirements"></a>Requirements

Before the ODB, Ops Manager controlled the IP allocation of the private networks.
So when using the ODB in a tile, you need at least two private networks:

- A network where Ops Manager will deploy the on-demand broker VM
- A different network where the on-demand broker will deploy service instance VMs

The network for service instances should be flagged as a Service Network in Ops Manager.

## <a id="deploying"></a>Deploy Ops Manager to AWS

1. Follow the default Ops Manager deployment 
[documentation](https://docs.pivotal.io/pivotalcf/customizing/cloudform-template.html), 
but with these modifications:
  
  1. Create a self-signed wildcard SSL certificate for a domain you control.
     This is usually `*.SOME-SUBDOMAIN.cf-app.com`.
     Upload the certificate (along with the associated private key) to AWS. 
     For details, see [SSL/TLS Certificates for Classic Load 
     Balancers](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ssl-server-cert.html#create-cert).
  
  1. Download the CloudFormation JSON and save it in the Ops Manager directory.
  
  1. Run the CloudFormation stack. Save any pertinent inputs (e.g BOSH DB credentials) 
  you type into the web console 
  in the Ops Manager directory for safe keeping (for example, in `info.txt`).
  
  1. Launch an instance of the AMI. 
  If possible, use an elastic IP so that you can always keep the same DNS record
  even if you recreate the VM. Failing that, auto-assign a public IP.
  
  1. Create a DNS record for `pcf.WILDCARD-CERTIFICATE-DOMAIN`. 
  To use the earlier example, the record will be for `pcf.some-subdomain.cf-app.com`. 
  It should point to the public IP of the Ops Manager VM.

1. Continue following the docs to log in to Ops Manager. Save the login credentials.

1. Configure the BOSH Director tile.

1. Click **Apply Changes**, and record the BOSH init manifest for future reference. 
   For example, copy the manifest to your local machine, with the following command:

    ```
    scp -i PRIVATE-KEY.pem ubuntu@OPSMAN-IP:/var/tempest/workspaces/default/deployments/bosh.yml bosh.yml
    ```

<p class="note"><strong>Note</strong>: 
  The ELBs created by CloudFormation are both for CF, not Ops Manager. 
  One of them will be configured with your wildcard certificate. 
  This takes the place of HAProxy in AWS PCF deployments, 
  and is therefore not used until you deploy the ERT tile.</p>

###<a id="target_bosh"></a>Target the BOSH Director

To target the BOSH Director from the Ops Manager VM, use a command like the following:

<pre class="terminal">
  $ bosh2 --ca-cert /var/tempest/workspaces/default/root_ca_certificate -e 10.0.16.10 alias-env om-director
</pre>

Thereafter, use `bosh2 -e om-director` to make requests to the BOSH Director.

## <a id="building"></a>Build a Tile for an On-Demand Service

To build a tile for an on-demand service, do the following:

1. Use the Tile Generator to to build your tile.
For instructions, see [How to Use](http://docs.pivotal.io/tiledev/tile-generator.html#how-to).

1. Add accessors to the tile metadata file, named `tile.yml` if you used the Tile Generator.
For a list of accessors you must add, see [Add Accessors to the Tile Metadata File](#accessors) below.

## <a id="accessors"></a>Add Accessors to the Tile Metadata File

The on-demand broker requires tiles to be configured with some information that 
is not accessible to operators.
This configuration information must be supplied using tile accessors.

You must add the following accessors to your on-demand tile:

<p class="note"><strong>Note</strong>: The accessors in this section are mandatory.
  For other accessors, see 
  <a href="https://docs.pivotal.io/tiledev/product-template-reference.html#ops-man-snippets">
    Ops Manager Provided Snippets</a>.</p>

### director

Ops Manager uses these accessors to get values relating to the BOSH Director installation.
For the on-demand broker to interact with BOSH Director, on-demand service tiles 
must be configured with credentials for managing BOSH deployments.  

The following table lists the accessors you must add:

| Accessor                  | Description                                                                                                                    |
|:--------------------------|:-------------------------------------------------------------------------------------------------------------------------------|
| $director.hostname        | The director's hostname or IP address                                                                                                      |
| $director.ca\_public\_key | The director's root ca certificate. Related: [Configure SSL Certificates](operating.html#ssl-certs). |

For example

```yaml
bosh:
  url: https://(( $director.hostname )):25555
  root_ca_cert: (( $director.ca_public_key ))
```

To see this example in context, see the 
[example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L104-L106).

### self

Ops Manager uses these accessors to get values that have been assigned to the tile after installation.
To enable `$self` accessors, set `service_broker: true` at the top level of your
tile metadata file.

<p class="note"><strong>Note</strong>: Setting <code>service_broker: true</code>
  will cause the BOSH Director to redeploy when installing or uninstalling the tile.</p>

The following table lists the accessors you must add:

| Accessor                  | Description                                                     |
|:--------------------------|:----------------------------------------------------------------|
| $self.uaa\_client_name    | UAA client name, that can authenticate with the BOSH Director   |
| $self.uaa\_client\_secret | UAA client secret, that can authenticate with the BOSH Director |
| $self.stemcell\_version   | The stemcell that the service deployment uses                   |
| $self.service\_network    | Service network configured for the on-demand instances          |

The service network has to be created manually. 
Create a subnet on AWS and then add it to the director. 
In the BOSH Director tile, under Create Networks > ADD network > fill in the subnet/vpc details.

For example

```yaml
bosh:
  authentication:
    uaa:
      url: https://(( $director.hostname )):8443
      client_id: (( $self.uaa_client_name ))
      client_secret: (( $self.uaa_client_secret ))
```

To see this example in context, see the 
[example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L107-L111).

### (Optional) cf

Ops Manager uses these accessors to get values from the PAS (or Elastic Runtime) tile.
If you want to use Pivotal Application Service (PAS) or Elastic Runtime, add 
these accessors to your tile metadata file.

The following table lists the accessors you must add to use PAS (or Elastic Runtime):

| Accessor                                        | Description                                                                        |
|:------------------------------------------------|:-----------------------------------------------------------------------------------|
| ..cf.ha\_proxy.skip\_cert\_verify.value         | Flag to skip SSL certificate verification for connections to the CF API            |
| ..cf.cloud\_controller.apps\_domain.value       | The application domain configured in the CF installation                           |
| ..cf.cloud\_controller.system\_domain.value     | The system domain configured in the CF installation                                |
| ..cf.uaa.system\_services\_credentials.identity | Username of a CF user in the cloud\_controller.admin group, to be used by services |
| ..cf.uaa.system\_services\_credentials.password | Password of a CF user in the cloud\_controller.admin group, to be used by services |

For example

```yaml
disable_ssl_cert_verification: (( ..cf.ha_proxy.skip_cert_verify.value ))
cf:
  url: https://api.(( ..cf.cloud_controller.system_domain.value ))
  authentication:
    url: https://uaa.(( ..cf.cloud_controller.system_domain.value ))
    user_credentials:
      username: (( ..cf.uaa.system_services_credentials.identity ))
      password: (( ..cf.uaa.system_services_credentials.password ))
```

To see this example in context, see the
[example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L103-L119).

## <a id="public-ip"></a>Allow Public IP Addresses for On-Demand Service Instance Groups

Ops Manager v1.9 and later provides a VM extension called `public_ip` in the BOSH Director's cloud config.
This can be used in the on-demand service broker's manifest to give instance groups a public IP address. 
This IP is only used for outgoing traffic to the internet from VMs with the `public_ip` extension. 
All internal traffic / incoming connections need to go over the private IP.

To allow operators to a assign public IP address to an on-demand service instance group,
do the following:

1. Update the tile handcraft file to include the following:

    ```
    form_types:
    - name: example_form
      property_inputs:
      - reference: .broker.example_vm_extensions
        label: VM options
        description: List of VM options for Service Instances

    job_types:
    - name: broker
      templates:
      - name: broker
        release: on-demand-service-broker
        manifest: |
          service_catalog:
            plans:
            - name: example-plan
              instance_groups:
              - name: example-instance-group
                vm_extensions: (( .broker.example_vm_extensions.value ))
      property_blueprints:
      - name: example_vm_extensions
        type: multi_select_options
        configurable: true
        optional: true
        options:
        - name: "public_ip"
          label: "Internet Connected VMs (on supported IaaS providers)"
    ```

## <a id="floating-stemcell"></a>Enable Floating Stemcells

Ops Manager provides a feature called [Floating 
Stemcells](https://docs.pivotal.io/pivotalcf/1-9/customizing/understanding-stemcells.html) 
that allows PCF to quickly propagate a patched stemcell to all VMs in the deployment 
that have the same compatible stemcell. 
Both the broker deployment and the service instances deployed by the On-Demand 
Broker can make use of this feature. 
Enabling this feature can help ensure that all of your service instances are patched to the latest stemcell.

For the service instances to be installed with the latest stemcell automatically,
ensure that the `upgrade-all-service-instances` errand is ticked.

To enable floating stemcells for your tile, do the following:

1. Implement floating stemcells in `handcraft.yml`.
<br><br>
For example:

    ```
    job_types:
      templates:
      - name: broker
        manifest: |
          service_deployment:
            releases:
            - name: release-name
              version: 1.0.0
              jobs: [job_server]
            stemcell:
              os: ubuntu-trusty
              version: (( $self.stemcell_version ))
    ```

1. Configure the `stemcell_criteria` in `binaries.yml`.
<br><br>
For example:

    ```
    ---
    name: example-on-demand-service
    product_version: 1.0.0
    stemcell_criteria:
      os: ubuntu-trusty
      version: '3312'
      enable_patch_security_updates: true
    ```

    <p class="note"><strong>Note</strong>: 
      Configuring this value to <code>false</code> disables this feature.</p>

## <a id="errands"></a>Add On-Demand Broker Lifecycle Errands

In the reference [Kafka tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile)
we have demonstrated how the errands in the on-demand broker release can be used.

The errands should be specified in the following order, as shown in the example Kafka tile:

Post-deploy:

- `register-broker`
- `upgrade-all-service-instances`

Pre-delete:

- `delete-all-service-instances-and-deregister-broker`

For more information about these errands, see [Broker and Service Management](./management.html).

### Upgrade All Service Instances Errand

The `upgrade-all-service-instances` errand can be configured with two
parameters:

- The number of simultaneous upgrades

- The number of canary instances

For more information about these parameters, see
[Upgrade All Service Instances](upgrades.html#upgrade-all-instances).

The example [Kafka
tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile)
shows how to create a tab with fields to configure the parameters for this errand.
The example tile has constraints to ensure the number of simultaneous
upgrades is greater than one and the number of canaries is greater than zero.

## <a id="secure-creds"></a>Allow Secure Binding

Runtime CredHub can securely store service instance credentials.
If secure binding is enabled, secure references to service credentials are passed 
through the network to the application container when users create bindings or service keys.

<p class="note"><strong>Note:</strong>
  To use the secure binding credentials feature you must use PCF 2.0 or later.</p>

To include the option to enable secure binding, update the tile metadata file as follows:

1. Add `secure_binding_credentials` to the top-level properties block in the on-demand broker manifest. 
For example:

    ```yaml
    secure_binding_credentials:
      enabled: true
      authentication:
        uaa:
          client_id: CREDHUB_CLIENT_ID # client ID used by broker when communicating with CredHub
          client_secret: CREDHUB_CLIENT_SECRET # client secret used by broker when communicating with CredHub
          ca_cert: UAA_CA_CERT
    ```

1. To let users enable and disable this feature in the Ops Manager UI, you need 
to make some changes to your tile's metadata file:

  1. Add a form field to allow the user to enable/disable secure bindings.  
  For an example form field, see the
  [example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L39-L46).
  <br><br>
  1. Add an element in `property_blueprints` that reads the setting in the form
  field and exposes the appropriate manifest snippet for CredHub and secure binding.  
  For an example `property_blueprints` section, see the
  [example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L606-L632).
  <br><br>
  1. Change the broker job so that it consumes the CredHub BOSH link from the
  `property_blueprints` section.  
  For an example broker job, see the
  [example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L96).
  <br><br>
  1. Change the broker job so that it consumes the generated secure bindings
  manifest snippet.  
  For an example broker job, see the
  [example-kafka-on-demand-tile](https://github.com/pivotal-cf-experimental/example-kafka-on-demand-tile/blob/e206e04a1eb80a5f53a5edd9a1f11e096bea5f4f/metadata_parts/handcraft.yml#L112).

